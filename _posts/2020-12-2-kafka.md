---
layout: post
title: kafka
keywords: kafka
description: kafka
categories: [message queue, kafka]
tags: [message queue, kafka]
---

# 什么是Apache kafka?
    
    由 Scala编写的Apache软件基金会开发的开源消息代理项目 ，并且是一个分布式的发布-订阅消息系统。
    
# Kafka中有哪几个组件?

    1.broker（代理）: broker 组成 kafka 集群的节点,之间没有主从关系, 依赖 zookeeper进行协调, broker 负责消息的读写与存储, 一个 broker 可以容纳多个 topic
    
    2.Producers（生产者）：消息生产者，就是向 kafka broker 发消息的客户端
    
    3.Consumer ：消费者使用一个 消费组 名称来进行标识，发布到topic中的每条记录被分配给订阅消费组中的一个消费者实例.消费者实例可以分布在多个进程中或者多个机器上。
                
                如果所有的消费者实例在同一消费组中，消息记录会负载平衡到每一个消费者实例.
                
                如果所有的消费者实例在不同的消费组中，每条消息记录会广播到所有的消费者进程.
    
    4.topic：一个topic可以认为是一类消息，消息以topic为类别记录,Kafka将消息种子(Feed)分门别类,每一类的消息称之为一个主题(topic)。Kafka 通过 topic 对存储的流数据进行分类。
    
    5.partition：Kafka集群将每个topic将被分成多个partition(区), 为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上。
    每一个partition都是一个有序的、不可变的消息序列，它在存储层面是以append log文件形式存在的。
    任何发布到此partition的消息都会被直接追加到log文件的尾部。每条消息在文件中的位置称为offset(偏移量)，offset为一个long型数字，它是唯一标记一条消息。
    
    6.replica：副本，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失且 kafka 仍然能够继续工作，
    kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本， 一个 leader 和若干个 follower。
    
    7.leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对 象都是 leader。
    
    8.follower：每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据 的同步。 leader 发生故障时，某个 follower 会成为新的 leader。
    
# kafka适合怎样的场景？

    1.构造实时流数据管道，它可以在系统或应用之间可靠地获取数据。 (相当于message queue)
    
    2.构建实时流式应用程序，对这些流数据进行转换或者影响。 (就是流处理，通过kafka stream topic和topic之间内部进行变化)
    
# kafka常用命令行

    创建主题
    kafka-topics.sh --zookeeper localhost:2181 --create --topic my-topic --replication-factor 3 --partitions 3
    
    查看主题列表
    kafka-topics.sh --zookeeper localhost:2181 --list
    
    查看主题状态
    kafka-topics.sh --describe  --zookeeper 127.0.0.1:2181 --topic TestTopic 
    
    发送消息（注意端口号为配置文件里面的端口号）
    ./kafka-console-producer.sh --broker-list localhost:9092 --topic test
    
    消费消息（可能端口号与配置文件保持一致，或与发送端口保持一致）
    ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning   #加了--from-beginning 重头消费所有的消息
    ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test         #不加--from-beginning 从最新的一条消息开始消费
                                                               
# kafka如何代码实现查看主题列表？

    <dependency>
        <groupId>org.springframework.kafka</groupId>
    	<artifactId>spring-kafka</artifactId>
    </dependency>
    
    Properties properties =  new Properties();
    properties.put("bootstrap.servers", "10.0.59.11:9093");
    properties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
    properties.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
    AdminClient adminClient = AdminClient.create(properties);
    ListTopicsResult result = adminClient.listTopics();
    KafkaFuture<Set<String>> names = result.names();
    try {
        names.get().forEach((k)->{
        System.out.println(k);
        });
    } catch (InterruptedException | ExecutionException e) {
        e.printStackTrace();
    }
    adminClient.close();
    
# kafka中的pull和push

     选择由producer向broker push消息并由consumer从broker pull消息。
     
 push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。  
 
 push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。 
 而pull模式则可以根据consumer的消费能力以适当的速率消费消息。
 
    缺点：
    基于pull模式不足之处在于，如果broker没有数据，消费者会轮询，直到数据到达，为了避免这种情况，我们允许消费者在pull请求时候使用“long poll”进行阻塞，直到数据到达 。
    

# kakfa中zookeeper的作用

Zookeeper 是一个开放源码的、高性能的协调服务，它用于 Kafka 的分布式应用。
Producer 直接连接 Broker，而kafaka集群的 broker，和 Consumer 都需要连接 Zookeeper。

    1.对于Broker
        状态：zookeeper 记录了所有 broker 的存活状态，broker 会向 zookeeper 发送心跳请求来上报自己的状态。
                zookeeper 维护了一个正在运行并且属于集群的 broker 列表。
                
        控制器选举：
            kafka 集群中有多个 broker，其中有一个会被选举为控制器。
            控制器负责管理整个集群所有分区和副本的状态，例如某个分区的 leader 故障了，控制器会选举新的 leader。
            从多个 broker 中选出控制器，这个工作就是 zookeeper 负责的。
        
        限额权限：
            kafka 允许一些 client 有不同的生产和消费的限额。
            这些限额配置信息是保存在 zookeeper 里面的。
            所有 topic 的访问控制信息也是由 zookeeper 维护的。
            
        记录 ISR:
            ISR（in-sync replica） 是 partition 的一组同步集合，就是所有 follower 里面同步最积极的那部分。
            一条消息只有被 ISR 中的成员都接收到，才被视为“已同步”状态。
            只有处于 ISR 集合中的副本才有资格被选举为 leader。
            zookeeper 记录着 ISR 的信息，而且是实时更新的，只要发现其中有成员不正常，马上移除。
            
        node 和 topic 注册
            zookeeper 保存了所有 node 和 topic 的注册信息，可以方便的找到每个 broker 持有哪些 topic。
            node 和 topic 在 zookeeper 中是以临时节点的形式存在的，只要与 zookeeper 的 session 一关闭，他们的信息就没有了。
        
        topic 配置:
            zookeeper 保存了 topic 相关配置，例如 topic 列表、每个 topic 的 partition 数量等等。
            
    2.对于Consumer
        注册：
            和 broker 一样，consumer 也需要注册。
            consumer 会自动注册，注册的方式也是创建一个临时节点，consumer down 了之后就会自动销毁。
            kafka 的每个 partition 只能被消费组中的一个 consumer 消费，kafka 必须知道所有 partition 与 consumer 的关系。
            
        offsets:
            旧的consumer依赖于Zookeeper来进行group管理, 新的消费者使用kafka内部的group coordination协议. 对于每个group, brokers中的一个被选为group coordinator. 
            
   
            主要用于offset位移管理和Consumer Rebalance。
            这个coordinator负责管理group的状态, 它的主要工作是当新的成员加入, 或者原本的成员离开, 或者topic的元数据发生了改变时, 协调partition分配. 重新分配partition这个过程被称为rebalancing the group.
                
            将 topic 的 offset 信息由之前存储在 zookeeper(/consumers/<group.id>/offsets/<topic>/<partitionId>,zk写操作性能不高) 上改为存储到一个特殊的 topic 中（__consumer_offsets）
            
# kafka中的ISR、AR又代表什么？ISR伸缩又是什么？

    分区中的所有副本统称为AR（Assigned Repllicas）。所有与leader副本保持一定程度同步的副本（包括Leader）组成ISR（In-Sync Replicas），ISR集合是AR集合中的一个子集。
    
    消息会先发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步，同步期间内follower副本相对于leader副本而言会有一定程度的滞后。
    
    前面所说的“一定程度”是指可以忍受的滞后范围，这个范围可以通过参数进行配置。
    
    与leader副本同步滞后过多的副本（不包括leader）副本，组成OSR(Out-Sync Relipcas),由此可见：AR=ISR+OSR。在正常情况下，所有的follower副本都应该与leader副本保持一定程度的同步，即AR=ISR,OSR集合为空。
    
    
# 如果leader crash时，ISR为空怎么办？

    kafka在Broker端提供了一个配置参数：unclean.leader.election,这个参数有两个值：
    true（默认）：允许不同步副本成为leader，由于不同步副本的消息较为滞后，此时成为leader，可能会出现消息不一致的情况。
    false：不允许不同步副本成为leader，此时如果发生ISR列表为空，会一直等待旧leader恢复，降低了可用性。
    
# 在生产者中,什么时候发生QueueFullException?
    
    当生产者尝试以代理（broker）无法处理的速度发送消息时，通常会发生QueueFullException。
    由于生产者没有阻止，用户将需要添加足够的代理来协作处理增加的负载。
    
# kafka如何保证消息的顺序性？
场景一：kafka只能保证partition内部有序，能需要顺序的数据分布到了不同的partition，导致处理时乱序
    
    解决方案：
        1、可以设置topic 有且只有一个partition
        2、根据业务需要，需要顺序的 指定为同一个partition


场景二：消费者里可能会搞多个线程来并发处理消息，顺序可能错乱

    解决方案：
        1.一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。
        2.写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。
        
# kafka为什么不支持读写分离？

    1.数据一致性问题。数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间 窗口会导致主从节点之间的数据不一致。
    某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。
    
    2.延时问题。类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经 历网络→主节点内存→网络→从节点内存这几个阶段，整个过程会耗费一定的时间。
    而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节 点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。
    
    主写从读可以均摊一定的负载却不能做到完全的负载均衡，比如对于数据写压力很大而读 压力很小的情况，从节点只能分摊很少的负载压力，而绝大多数压力还是在主节点上。
    而在 Kafka 中却可以达到很大程度上的负载均衡，而且这种均衡是在主写主读的架构上实现的。       
  
总的来说，Kafka 只支持主写主读有几个优点:

    1.可以简化代码的实现逻辑，减少出错的可能;
    
    2.将负载粒度细化均摊，与主写从读相比，不仅负载效能更好，而且对用户可控;
    
    3.没有延时的影响;
    
    4.在副本稳定的情况下，不会出现数据不一致的情况。
    
#kafka如何实现负载均衡的？
1.分区器

    分区器是生产者层面的负载均衡。Kafka 生产者生产消息时，根据分区器将消息投递到指定的分区中，所以 Kafka 的负载均衡很大程度上依赖于分区器。
    Kafka 默认的分区器是 Kafka 提供的 DefaultPartitioner。
    它的分区策略是根据 Key 值进行分区分配的：
    
    如果 key 不为 null：对 Key 值进行 Hash 计算，从所有分区中根据 Key 的 Hash 值计算出一个分区号；拥有相同 Key 值的消息被写入同一个分区；
    如果 key 为 null：消息将以轮询的方式，在所有可用分区中分别写入消息。
    
2.消费者再均衡

    Kafka 通过 消费组协调器 (GroupCoordinator) 与消费者协调器 (ConsumerCoordinator)，实现消费者再均衡操作。
    
    1.消费组协调器 (GroupCoordinator)：Kafka 服务端中，用于管理消费组的组件；
    2.消费者协调器 (ConsumerCoordinator)：Consumer 客户端中，负责与 GroupCoordinator 进行交互；
ConsumerCoordinator 与 GroupCoordinator 之间最重要的职责就是负责执行消费者再均衡操作。
导致消费者再均衡的操作：
    
    1.新的消费者加入消费组；
    2.消费者宕机下线（不一定是真的下线，令消费组以为消费者宕机下线的本质原因是消费者长时间未向 GroupCoordinator 发送心跳包）
    3.消费者主动退出消费组；
    4.消费组对应的 GroupCoordinator 节点发生了变更；
    5.任意主题或主题分区数量发生变化。


    
                 
         
    